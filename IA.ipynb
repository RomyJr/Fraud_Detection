{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partie IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import seaborn as sns  # Pour la visualisation statistique\n",
    "import matplotlib.pyplot as plt  # Pour créer des graphiques\n",
    "import pandas as pd  # Pour manipuler les données sous forme de DataFrame\n",
    "from IPython.display import display, HTML  # Pour afficher du HTML dans un notebook Jupyter\n",
    "import warnings  # Pour gérer les avertissements\n",
    "\n",
    "# Importation des modules de Scikit-learn pour la transformation des colonnes, pipelines, modèles et évaluation\n",
    "from sklearn.compose import ColumnTransformer  # Pour appliquer des transformations différentes sur les colonnes\n",
    "from sklearn.pipeline import Pipeline  # Pour créer des pipelines de transformations et de modèles\n",
    "from sklearn.preprocessing import StandardScaler  # Pour le prétraitement des données\n",
    "from sklearn.model_selection import train_test_split  # Pour la division des données et la recherche des hyperparamètres\n",
    "from sklearn.metrics import accuracy_score, classification_report  # Pour évaluer les performances du modèle\n",
    "from catboost import CatBoostClassifier  # Classifieur CatBoost\n",
    "\n",
    "# Ignorer certains avertissements\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(r'C:\\Users\\colin\\Documents\\ESEO\\E5\\docsPFE\\creditcard_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en caractéristiques (X) et cible (y)\n",
    "X = df_tr.drop('Class', axis=1)\n",
    "y = df_tr['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. df_tr.drop('Class', axis=1) :\n",
    "        La méthode .drop() permet de supprimer une colonne spécifique du DataFrame.\n",
    "        Ici, la colonne 'Class' (la variable cible) est supprimée du DataFrame df_tr pour créer l'ensemble des caractéristiques X.\n",
    "        Le paramètre axis=1 indique que l'on supprime une colonne (et non une ligne).\n",
    "        Résultat : X contient toutes les colonnes de df_tr à l'exception de la colonne 'Class'.\n",
    "\n",
    "2. df_tr['Class'] :\n",
    "        Ce code extrait uniquement la colonne 'Class' de df_tr, qui est assignée à la variable y, représentant la variable cible.\n",
    "        Résultat : y contient les valeurs de la colonne 'Class', c'est-à-dire la variable que le modèle tentera de prédire.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "> X : Contient toutes les colonnes de caractéristiques (features) à partir desquelles le modèle apprendra (toutes les colonnes sauf 'Class').<br>\n",
    "> y : Contient la colonne 'Class', qui est la cible que l'on cherche à prédire (par exemple, pour un problème de classification binaire).\n",
    "\n",
    "Ce processus est typique dans les tâches de machine learning, où on sépare les caractéristiques des étiquettes (target) avant d'entraîner un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les caractéristiques numériques (exclure les colonnes catégorielles)\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. X.select_dtypes(include=['int64', 'float64']) :\n",
    "        La méthode select_dtypes() permet de sélectionner uniquement les colonnes d'un certain type dans un DataFrame.\n",
    "        Ici, le paramètre include=['int64', 'float64'] indique que seules les colonnes de type entier (int64) et flottant (float64) seront sélectionnées.\n",
    "        Cela permet d'exclure automatiquement toutes les colonnes contenant des données catégorielles ou d'autres types non numériques, comme des chaînes de caractères (object) ou des booléens.\n",
    "\n",
    "2. .columns.tolist() :\n",
    "        La propriété .columns récupère les noms des colonnes sélectionnées dans le DataFrame.\n",
    "        La méthode .tolist() convertit cette liste d'objets Index en une liste Python standard.\n",
    "\n",
    "3. numeric_features :\n",
    "        La variable numeric_features contiendra donc la liste des noms de toutes les colonnes numériques (entiers et flottants) dans X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le pipeline de transformation pour les colonnes numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline :\n",
    "\n",
    "> Un pipeline est une séquence d'étapes appliquées aux données, chacune représentant une transformation.\n",
    "\n",
    "> Ici, il s'agit de définir un pipeline pour les caractéristiques numériques.\n",
    "\n",
    "steps=[('scaler', StandardScaler())] :\n",
    "\n",
    "> StandardScaler() est un transformateur qui normalise les données en les centrant sur la moyenne 0 et en les réduisant à une échelle unitaire (écart-type 1). Cela est souvent nécessaire avant de passer à des algorithmes d'apprentissage automatique, car certains modèles sont sensibles à l'échelle des données (par exemple, les modèles basés sur la distance comme la régression logistique, SVM, etc.).\n",
    "> Le pipeline comporte une étape unique ici : la normalisation des colonnes numériques avec le StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la transformation par colonnes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnTransformer :\n",
    "\n",
    "> Il permet d'appliquer des transformations spécifiques à des sous-ensembles de colonnes d'un DataFrame. Cela est utile quand il y a un mélange de colonnes numériques et catégorielles nécessitant des prétraitements différents.\n",
    "\n",
    "transformers=[...] :\n",
    "\n",
    "> Ici, on spécifie que l'on veut appliquer des transformations aux colonnes numériques.\n",
    "\n",
    "> ('num', numeric_transformer, numeric_features) :\n",
    ">> 'num' : C'est une étiquette de nommage arbitraire pour cette transformation (utile pour identifier les étapes).\n",
    ">> numeric_transformer : Le pipeline défini précédemment qui contient l'étape de mise à l'échelle des données numériques.\n",
    ">> numeric_features : La liste des colonnes numériques sur lesquelles on applique cette transformation (sélectionnées plus tôt avec select_dtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                         ('classifier', CatBoostClassifier(verbose=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split :\n",
    "    Cette fonction provient de la bibliothèque sklearn.model_selection et est utilisée pour diviser les données en deux ensembles distincts : un pour l'entraînement du modèle et un autre pour le test du modèle.\n",
    "    Cela permet d'évaluer la performance du modèle sur des données qu'il n'a pas vues pendant l'entraînement, assurant ainsi que le modèle ne soit pas simplement surajusté (overfitted) aux données d'entraînement.\n",
    "\n",
    "Paramètres de train_test_split :\n",
    "    X : C'est le DataFrame contenant les caractéristiques (features) d'entrée.\n",
    "    y : C'est la série contenant la variable cible (target) à prédire.\n",
    "    test_size=0.2 :\n",
    "        Ce paramètre spécifie la proportion de l'ensemble de données qui doit être utilisée comme ensemble de test.\n",
    "        Ici, 20% des données seront utilisées pour le test, tandis que les 80% restants seront utilisés pour l'entraînement.\n",
    "    random_state=42 :\n",
    "        Ce paramètre fixe le graine aléatoire pour la génération de nombres aléatoires. Cela permet d'obtenir des résultats reproductibles.\n",
    "        En utilisant une valeur fixe (comme 42 ici), chaque fois que vous exécuterez ce code, vous obtiendrez la même division entre les ensembles d'entraînement et de test.\n",
    "\n",
    "Variables résultantes :\n",
    "    X_train : Contient les caractéristiques des données d'entraînement.\n",
    "    X_test : Contient les caractéristiques des données de test.\n",
    "    y_train : Contient les étiquettes (cibles) des données d'entraînement.\n",
    "    y_test : Contient les étiquettes (cibles) des données de test.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "Ce code divise l'ensemble de données en deux parties : 80% pour l'entraînement et 20% pour le test.\n",
    "Cela est essentiel pour évaluer correctement les performances d'un modèle de machine learning, en s'assurant que les évaluations de performance (précision, rappel, etc.) ne soient pas biaisées par l'utilisation des mêmes données pour l'entraînement et le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(...) :\n",
    "    La méthode fit() est utilisée pour entraîner le modèle sur les données d'entraînement.\n",
    "    Cela implique que le modèle va apprendre à partir des caractéristiques (X_train) et des étiquettes cibles (y_train) fournies.\n",
    "\n",
    "Données d'entraînement :\n",
    "    X_train : Contient les caractéristiques (features) d'entrée qui seront utilisées pour prédire les cibles. Chaque ligne représente un exemple d'entraînement, et chaque colonne représente une caractéristique.\n",
    "    y_train : Contient les étiquettes (targets) correspondantes pour chaque exemple d'entraînement dans X_train. Cela signifie que pour chaque ensemble de caractéristiques dans X_train, il y a une étiquette correspondante dans y_train que le modèle doit apprendre à prédire.\n",
    "\n",
    "Que se passe-t-il lors de l'exécution de fit() ?\n",
    "\n",
    "Apprentissage : Le modèle (dans ce cas, un CatBoostClassifier) va parcourir les données d'entraînement, analyser les relations entre les caractéristiques et les cibles, et ajuster ses paramètres internes en conséquence.\n",
    "Optimisation : Le modèle utilise des algorithmes d'optimisation pour minimiser la fonction de perte, qui quantifie à quel point les prédictions du modèle s'écartent des valeurs réelles de y_train.\n",
    "Stockage des paramètres : Après l'entraînement, le modèle mémorise les informations nécessaires pour faire des prédictions sur de nouvelles données.\n",
    "\n",
    "Importance de cette étape\n",
    "\n",
    "Entraînement du modèle : C'est une étape essentielle dans le processus de machine learning, car c'est à ce moment-là que le modèle apprend à partir des données.\n",
    "Préparation pour la prédiction : Une fois le modèle entraîné, il peut être utilisé pour faire des prédictions sur des données non vues (comme celles dans X_test) en utilisant la méthode predict().\n",
    "\n",
    "En résumé :\n",
    "\n",
    "Ce code entraîne le modèle défini précédemment en utilisant les données d'entraînement.\n",
    "Une fois cette étape terminée, le modèle est prêt à faire des prédictions sur de nouvelles données en fonction des relations qu'il a apprises lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.predict(...) :\n",
    "    La méthode predict() est utilisée pour générer des prédictions basées sur les caractéristiques de l'ensemble de test.\n",
    "    Elle prend en entrée X_test, qui contient les caractéristiques des exemples de test que le modèle n'a jamais vus auparavant.\n",
    "\n",
    "Données de test :\n",
    "    X_test : Contient les caractéristiques des données qui seront utilisées pour évaluer la performance du modèle. Chaque ligne dans X_test représente un exemple sur lequel le modèle doit faire des prédictions.\n",
    "\n",
    "Résultats des prédictions :\n",
    "    y_pred : C'est un tableau ou une série qui contient les prédictions du modèle pour chaque exemple de test. Chaque valeur dans y_pred correspond à la classe ou la valeur prédite pour l'exemple de test correspondant dans X_test.\n",
    "\n",
    "Que se passe-t-il lors de l'exécution de predict() ?\n",
    "\n",
    "Génération des prédictions : Le modèle utilise les paramètres qu'il a appris lors de l'entraînement pour prédire la cible (classe ou valeur) de chaque exemple dans X_test.\n",
    "Utilisation des caractéristiques : Pour chaque exemple dans X_test, le modèle applique les relations qu'il a apprises entre les caractéristiques et la variable cible.\n",
    "\n",
    "Importance de cette étape\n",
    "\n",
    "Évaluation des performances : Les prédictions effectuées sur l'ensemble de test (stockées dans y_pred) sont essentielles pour évaluer la performance du modèle en les comparant aux vraies valeurs de cibles correspondantes dans y_test.\n",
    "Vérification de l'efficacité : Cela permet d'analyser la capacité du modèle à généraliser et à faire des prédictions sur des données qu'il n'a pas vues, ce qui est crucial pour comprendre sa performance dans des scénarios réels.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "Ce code génère des prédictions pour l'ensemble de test en utilisant le modèle de machine learning déjà entraîné.\n",
    "Les résultats sont stockés dans y_pred, ce qui permettra de les comparer aux vraies cibles pour évaluer la précision et l'efficacité du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9996570705027874\n"
     ]
    }
   ],
   "source": [
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_score(...) :\n",
    "    accuracy_score est une fonction provenant de la bibliothèque sklearn.metrics. Elle est utilisée pour évaluer la performance du modèle en calculant l'exactitude des prédictions.\n",
    "    La fonction prend deux arguments :\n",
    "        y_test : Ce sont les vraies valeurs de la cible pour l'ensemble de test.\n",
    "        y_pred : Ce sont les valeurs prédites par le modèle sur le même ensemble de test.\n",
    "\n",
    "Calcul de l'exactitude :\n",
    "    L'exactitude est définie comme le rapport du nombre de prédictions correctes au nombre total de prédictions effectuées. Elle peut être calculée comme suit :\n",
    "Accuracy=Nombre de preˊdictions correctesNombre total de preˊdictions\n",
    "Accuracy=Nombre total de preˊdictionsNombre de preˊdictions correctes​\n",
    "    Une exactitude de 1 (ou 100%) signifie que toutes les prédictions étaient correctes, tandis qu'une exactitude de 0 signifie que le modèle n'a fait aucune prédiction correcte.\n",
    "\n",
    "Stockage du résultat :\n",
    "    accuracy : Cette variable stocke la valeur de l'exactitude calculée, qui peut ensuite être utilisée pour des analyses ou des comparaisons ultérieures.\n",
    "\n",
    "Affichage du résultat :\n",
    "    print(\"Accuracy:\", accuracy) : Cela affiche la valeur de l'exactitude dans la console. Le texte \"Accuracy:\" est suivi de la valeur de l'exactitude calculée.\n",
    "\n",
    "Importance de cette étape\n",
    "\n",
    "Évaluation de la performance : L'exactitude est une métrique couramment utilisée pour évaluer les modèles de classification. Elle fournit une indication générale de la performance du modèle.\n",
    "Comparaison de modèles : L'exactitude permet de comparer la performance de différents modèles ou configurations de modèles afin de sélectionner celui qui donne les meilleurs résultats.\n",
    "Limites : Bien que l'exactitude soit une mesure utile, elle peut parfois être trompeuse, surtout dans des ensembles de données déséquilibrés (où certaines classes sont beaucoup plus fréquentes que d'autres). Dans ces cas, d'autres métriques comme la précision, le rappel ou le score F1 peuvent être plus informatives.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "Ce code calcule l'exactitude du modèle sur l'ensemble de test en comparant les valeurs prédites aux vraies valeurs.\n",
    "Le résultat est stocké dans la variable accuracy et est ensuite affiché à l'utilisateur, ce qui fournit une mesure directe de la performance du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[44m\u001b[37mClassification Report\u001b[0m\n",
      "Class 0:\n",
      "  Precision: \u001b[32m1.00\u001b[0m\n",
      "  Recall: \u001b[32m1.00\u001b[0m\n",
      "  F1-score: \u001b[32m1.00\u001b[0m\n",
      "  Support: 56750.0\n",
      "Class 1:\n",
      "  Precision: \u001b[32m1.00\u001b[0m\n",
      "  Recall: \u001b[32m1.00\u001b[0m\n",
      "  F1-score: \u001b[32m1.00\u001b[0m\n",
      "  Support: 56976.0\n",
      "accuracy: 0.9996570705027874\n",
      "macro avg: {'precision': 0.9996569545708367, 'recall': 0.9996571914660413, 'f1-score': 0.9996570692311153, 'support': 113726.0}\n",
      "weighted avg: {'precision': 0.999657078158671, 'recall': 0.9996570705027874, 'f1-score': 0.9996570705434346, 'support': 113726.0}\n"
     ]
    }
   ],
   "source": [
    "# Afficher le rapport de classification avec couleurs et en-tête\n",
    "from colorama import Fore, Back, Style\n",
    "print(\"\\n\" + Back.BLUE + Fore.WHITE + \"Classification Report\" + Style.RESET_ALL)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "for key, value in report.items():\n",
    "    if key in ['0', '1']:  \n",
    "        color = Fore.GREEN if value['precision'] > 0.8 else Fore.RED\n",
    "        print(f\"Class {key}:\")\n",
    "        print(f\"  Precision: {color}{value['precision']:.2f}{Style.RESET_ALL}\")\n",
    "        color = Fore.GREEN if value['recall'] > 0.8 else Fore.RED\n",
    "        print(f\"  Recall: {color}{value['recall']:.2f}{Style.RESET_ALL}\")\n",
    "        color = Fore.GREEN if value['f1-score'] > 0.8 else Fore.RED\n",
    "        print(f\"  F1-score: {color}{value['f1-score']:.2f}{Style.RESET_ALL}\")\n",
    "        print(f\"  Support: {value['support']}\")\n",
    "    else:\n",
    "        print(key + \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des modules :\n",
    "    from colorama import Fore, Back, Style : La bibliothèque colorama est utilisée pour ajouter des couleurs et des styles au texte imprimé dans la console.\n",
    "    Fore : Définit les couleurs de premier plan (texte).\n",
    "    Back : Définit les couleurs d'arrière-plan.\n",
    "    Style : Permet de réinitialiser les styles ou de définir des styles spéciaux.\n",
    "\n",
    "Affichage de l'en-tête :\n",
    "    print(\"\\n\" + Back.BLUE + Fore.WHITE + \"Classification Report\" + Style.RESET_ALL) :\n",
    "        Affiche un en-tête avec un fond bleu et du texte blanc pour indiquer le début du rapport de classification.\n",
    "        Style.RESET_ALL : Réinitialise le style à la valeur par défaut après l'impression de l'en-tête.\n",
    "\n",
    "Génération du rapport de classification :\n",
    "    report = classification_report(y_test, y_pred, output_dict=True) :\n",
    "        Cette ligne génère un rapport de classification à l'aide de la fonction classification_report de sklearn.metrics.\n",
    "        output_dict=True : Cela indique que le rapport doit être renvoyé sous forme de dictionnaire, ce qui facilite l'accès aux métriques pour chaque classe.\n",
    "\n",
    "Affichage des résultats par classe :\n",
    "    La boucle for key, value in report.items(): parcourt chaque élément du rapport.\n",
    "    Conditions pour les classes :\n",
    "        if key in ['0', '1']: : Cela vérifie si la clé représente une classe spécifique. Ici, les classes '0' et '1' sont traitées pour afficher des statistiques détaillées.\n",
    "\n",
    "Mise en forme colorée :\n",
    "    Pour chaque métrique (précision, rappel, score F1), la couleur du texte est définie en fonction de la valeur de la métrique :\n",
    "        Précision : Si elle est supérieure à 0.8, la couleur est verte ; sinon, elle est rouge.\n",
    "        Rappel : Même logique que pour la précision.\n",
    "        F1-score : Même logique que pour la précision et le rappel.\n",
    "    Chaque métrique est imprimée avec sa valeur formatée à deux décimales.\n",
    "\n",
    "Affichage du support :\n",
    "    print(f\" Support: {value['support']}\") : Affiche le nombre d'exemples pour chaque classe.\n",
    "\n",
    "Autres clés :\n",
    "    Si la clé ne correspond pas aux classes '0' ou '1', elle est simplement imprimée avec sa valeur.\n",
    "\n",
    "Importance de cette étape\n",
    "\n",
    "Évaluation détaillée : Le rapport de classification fournit des mesures clés pour chaque classe, ce qui permet d'évaluer la performance du modèle de manière détaillée.\n",
    "Analyse visuelle : L'utilisation de couleurs rend les résultats plus faciles à interpréter et à comprendre rapidement.\n",
    "Identification des classes problématiques : Les métriques comme la précision et le rappel permettent d'identifier les classes pour lesquelles le modèle pourrait avoir des difficultés, ce qui peut guider des ajustements futurs.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "Ce code génère et affiche un rapport de classification détaillé pour le modèle.\n",
    "Les métriques de performance sont présentées avec une mise en forme colorée pour faciliter l'analyse, permettant une évaluation rapide et efficace de la performance du modèle sur chaque classe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
